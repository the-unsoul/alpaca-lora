{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1VJ7lfTYz0qu",
    "outputId": "20b4c81d-5992-4c2a-a79f-a894ad7dba1c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip -q install git+https://github.com/huggingface/transformers # need to install from github\n",
    "!pip -q install datasets loralib sentencepiece \n",
    "!pip -q install bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MK_96JPU0fgQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "# import torch\n",
    "import textwrap\n",
    "import os.path as osp\n",
    "from typing import Union\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "dataset_name = 'flowbird-april--koala-7b'\n",
    "model_name = 'samwit/koala-7b'\n",
    "# model_name = 'chavinlo/alpaca-native'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lHAMGhEW0ldH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/uns/.local/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cpu.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: WARNING! libcuda.so not found! Do you have a CUDA driver installed? If you are on a cluster, make sure you are on a CUDA machine!\n",
      "CUDA SETUP: Loading binary /home/uns/.local/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cpu.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uns/.local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('unix')}\n",
      "  warn(msg)\n",
      "/home/uns/.local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('VSCODE_WSL_EXT_LOCATION/up')}\n",
      "  warn(msg)\n",
      "/home/uns/.local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/home/uns/go/bin')}\n",
      "  warn(msg)\n",
      "/home/uns/.local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "/home/uns/.local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "/home/uns/.local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib64')}\n",
      "  warn(msg)\n",
      "/home/uns/.local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: No libcudart.so found! Install CUDA or the cudatoolkit package (anaconda)!\n",
      "  warn(msg)\n",
      "/home/uns/.local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: No GPU detected! Check your CUDA paths. Proceeding to load CPU-only library...\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999346736706466aa8ad1bf7122b954b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(model_name)\n",
    "\n",
    "base_model = LlamaForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_8bit=True,\n",
    "    device_map='auto',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wJSkqjrYva2a",
    "outputId": "c75c91e8-7a05-40cb-94d9-a5a2e100f0a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 22 20:19:20 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.47                 Driver Version: 531.68       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090         On | 00000000:01:00.0  On |                  N/A |\n",
      "| 53%   43C    P5               39W / 350W|   9761MiB / 24576MiB |     19%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     12227      C   /python3.8                                N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "odWWkO_81HIl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 88.1 ms, sys: 20.4 ms, total: 109 ms\n",
      "Wall time: 179 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# decent configs\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=base_model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=612,\n",
    "    temperature=0.2,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "\n",
    "# default from https://www.youtube.com/watch?v=kSLcedGSez8&t=310s\n",
    "# pipe = pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=base_model, \n",
    "#     tokenizer=tokenizer, \n",
    "#     max_length=512,\n",
    "#     temperature=0.7,\n",
    "#     top_p=0.95,\n",
    "#     repetition_penalty=1.15\n",
    "# )\n",
    "\n",
    "\n",
    "# pipe = pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=base_model, \n",
    "#     tokenizer=tokenizer, \n",
    "#     max_length=512,\n",
    "#     temperature=0.3,\n",
    "#     top_p=0.95,\n",
    "#     repetition_penalty=1.1\n",
    "# )\n",
    "\n",
    "def wrap_text_preserve_newlines(text, width=110):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DE_cImNYcsAy"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Prompter(object):\n",
    "    __slots__ = (\"template\", \"_verbose\")\n",
    "\n",
    "    def __init__(self, template_name: str = \"\", verbose: bool = False, runner: str = 'google-colab'):\n",
    "        self._verbose = verbose\n",
    "        \n",
    "        base_path = '../templates/'\n",
    "        if runner == 'google-colab':\n",
    "            base_path = '/content/'\n",
    "        \n",
    "        \n",
    "        if not template_name:\n",
    "            # Enforce the default here, so the constructor can be called with '' and will not break.\n",
    "            template_name = \"alpaca\"\n",
    "        file_name = osp.join(base_path, f\"{template_name}.json\")\n",
    "        if not osp.exists(file_name):\n",
    "            raise ValueError(f\"Can't read {file_name}\")\n",
    "        with open(file_name) as fp:\n",
    "            self.template = json.load(fp)\n",
    "        if self._verbose:\n",
    "            print(\n",
    "                f\"Using prompt template {template_name}: {self.template['description']}\"\n",
    "            )\n",
    "\n",
    "    def generate_prompt(\n",
    "        self,\n",
    "        instruction: str,\n",
    "        input: Union[None, str] = None,\n",
    "        label: Union[None, str] = None,\n",
    "    ) -> str:\n",
    "        # returns the full prompt from instruction and optional input\n",
    "        # if a label (=response, =output) is provided, it's also appended.\n",
    "        if input:\n",
    "            res = self.template[\"prompt_input\"].format(\n",
    "                instruction=instruction, input=input\n",
    "            )\n",
    "        else:\n",
    "            res = self.template[\"prompt_no_input\"].format(\n",
    "                instruction=instruction\n",
    "            )\n",
    "        if label:\n",
    "            res = f\"{res}{label}\"\n",
    "        if self._verbose:\n",
    "            print(res)\n",
    "        return res\n",
    "\n",
    "    def get_response(self, output: str) -> str:\n",
    "        return output.split(self.template[\"response_split\"])[1].strip()\n",
    "\n",
    "question_prompter = Prompter(template_name=\"generate_question\", runner=\"local\")\n",
    "answer_prompter = Prompter(template_name=\"generate_answer\", runner=\"local\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data set\n",
    "\n",
    "\n",
    "dataset = []\n",
    "dataset_path = osp.join('../dataset/', f\"{dataset_name}.json\")\n",
    "\n",
    "\n",
    "try:\n",
    "    fp = open(dataset_path)\n",
    "    dataset = json.load(fp)\n",
    "except:\n",
    "    dataset = []    \n",
    "\n",
    "    \n",
    "def save_dataset():\n",
    "    with open(dataset_path, 'w') as fp:\n",
    "        json.dump(dataset, fp, ensure_ascii=False, indent=2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SITCakdmiogu"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_response(text: str):\n",
    "    splitted = text.split('### Response:\\n')\n",
    "    return splitted[1].strip()\n",
    "\n",
    "\n",
    "# def response_to_array(text: str):\n",
    "#     pattern = r'^d\\.\\s{3}'\n",
    "#     questions = text.rsplit(pattern);\n",
    "#     qs_cleaned = [];\n",
    "    \n",
    "#     for q in questions: \n",
    "#         q_cleaned = re.split(pattern, q)[1]\n",
    "#         qs_cleaned.append(q_cleaned)\n",
    "    \n",
    "#     return qs_cleaned\n",
    "\n",
    "def fix_encoding_output(text: str):\n",
    "    start_encode_pattern = r\"\\<ol start=\\\"(\\d)\\\"\\>\\<li\\>\"\n",
    "    end_encode_pattern = r\"\\<\\/li\\>\\<\\/ol\\>\"\n",
    "\n",
    "    text = re.sub(start_encode_pattern, r\"\\1.   \", text)\n",
    "    text = re.sub(end_encode_pattern, \"\", text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def response_to_array(text: str):\n",
    "    # clean up encoding issue\n",
    "\n",
    "    \n",
    "    \n",
    "    splitter_pattern = r\"^\\d.\\s{3}\"\n",
    "    responses_cleand = re.split(splitter_pattern, text, 0, re.MULTILINE);\n",
    "    return responses_cleand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_raw_text(text: str):\n",
    "    q_prompt = question_prompter.generate_prompt(\n",
    "        '',\n",
    "        text\n",
    "    )\n",
    "    output = pipe(q_prompt)\n",
    "    # print(wrap_text_preserve_newlines(output[0]['generated_text']))\n",
    "    \n",
    "\n",
    "    output[0]['generated_text'] = fix_encoding_output(output[0]['generated_text'])\n",
    "    questions = extract_response(output[0]['generated_text'])\n",
    "\n",
    "    questions_array = response_to_array(questions)\n",
    "    \n",
    "    \n",
    "    a_prompt = answer_prompter.generate_prompt(\n",
    "        text,\n",
    "        questions\n",
    "    )\n",
    "    output = pipe(a_prompt)\n",
    "    \n",
    "    output[0]['generated_text'] = fix_encoding_output(output[0]['generated_text'])\n",
    "    print('\\n\\n')\n",
    "    print(wrap_text_preserve_newlines(output[0]['generated_text']))\n",
    "    answers = extract_response(output[0]['generated_text'])\n",
    "\n",
    "    answers_array = response_to_array(answers)\n",
    "    \n",
    "    for i, q in enumerate(questions_array):\n",
    "        if not q:\n",
    "            continue\n",
    "        data = {\n",
    "            \"instruction\": questions_array[i],\n",
    "            \"input\": \"In context of Flowbird Group\",\n",
    "            \"output\": answers_array[i]\n",
    "        }\n",
    "        dataset.append(data);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    \"WE ARE FLOWBIRD\\nFlowbird offers end to end Smart mobility, Parking and Electric Vehicle charging solutions. We provide towns and cities with the tools to make mobility in urban areas simple, multimodal and environmentally friendly, and the ability to understand and manage this mobility.\\nPartnering with local administrations and operators for over 65 years, we provide apps, terminals, kerbside management, enforcement - and the software to manage these remotely. We upgrade existing physical terminals to digital terminals with new services and tariffs and open them up to integrate third party apps. Flowbird orchestrates sales, payments, reporting, invoices and fines across multiple endpoints, also providing the data insights needed to inform decisions.\\n\",\n",
      "    \"\\nFLOWBIRD global payment platform manages more than 300M banking transactions a year. Over 100 million users per week in 80+ countries trust Flowbird's expertise, R&D and technology partnerships to reduce air pollution, provide EV charging, upgrade terminals, optimize traffic, manage enforcement, simplify payments and make urban spaces more vibrant and secure.\\n\",\n",
      "    \"\\nFLOWBIRD MISSION\\nTo facilitate the individual journey and maximize a city's unique mobility potential, while considering all city stakeholders and end-user experiences. Through our devices, elite service platform and our teams, we enable a new era for maximizing urban harmony and value throughout the city's core.\\n\",\n",
      "    \"\\nFLOWBIRD CREATE SMART MOBILITY IN SMART CITIES\\nThe density of urban area continues to grow. The challenges of mobility are becoming crucial and communities all over the world are facing new trends, integrating or proposing new uses, a new way of living in the city. Multimodal and connected, the city of tomorrow will be \\u201csmart\\u201d or will not be!\\nFlowbird is the partner of cities for more than 60 years. It's unique portfolio of solutions , kiosks & mobile phone payment, are connected to a global technology platform delivering day to day benefits to end users and city decision makers.\\nWith Flowbird, the city becomes EASIER, SAFER, FASTER.\\n\",\n",
      "    \"\\nINNOVATION\\nFlowbird set a new business standard together with our customers. We continuously improve and renew our products, services and work methods in order to simplify people's everyday life and to become more effective and cost saving. We improve and invent new ways of packaging and offering our products and services.\\n\",\n",
      "    \"\\nOPENNESS\\nFlowbird has an open and straightforward communication with our customers and partners. We discuss challenges and opportunities openly within Flowbird. We offer open interfaces to our products and services in order to enable integration to other systems to create a higher value\\n\",\n",
      "    \"\\nRELIABILITY\\nCity services access are to be organized according users profiles and their city contributions. Our systems are the link between all the profiles and payments, offering the best service experience whilst ensuring city policies effectiveness. To support this approach we offer an ever-increasing number of payment & control methods.\\n\",\n",
      "    \"\\nWITH FLOWBIRD APP PARKING BECOMES EASIER.\\nFlowbird mobile app allows you to pay for parking in 3 simple steps. No more cash needed. Pay from anywhere. Avoid parking fines. No more waiting in line at the parking meter. Parking becomes easier, safer and faster with the Flowbird mobile app. Join our mobile parking community for free and experience the advantage of Flowbird.\\n\\n\",\n",
      "    \"\\nWHAT WE DO\\nAt Flowbird, we develop and improve our products together with our customers, mainly cities and private operators. Together we work to stay in the forefront of global trends and changes within the parking industry. We listen to the needs of our customers based on everyday experience of drivers/parkers. We ensure that we are continually working to improve technology in line with what motorists want in order to make parking a pleasant experience. All this helps us ensure that our concept remains successful in an ever-changing world and contributes to making cities connected and smarter.\\n\",\n",
      "    \"\\nINCREASED EFFICIENCY\\nInstead of paper tickets, payment is linked to the vehicle's registration number. Payment can be made via our mobile app or at a parking terminal. The parking user may have a valid residents permit for their vehicle. The parking enforcement officers scan the registration number and can then see whether the fee has been paid or not.\\n\",\n",
      "    \"\\nTOUCHSCREEN INTERFACE\\nTo address new digital behaviors and ensure the best user experience when it comes to parking payment and other services, Flowbird offers a secure 10-inch color touch screen that allows zooming, sliding,  and with interfaces and operating sequences similar to those of the mobile apps which users are already familiar with.\\n\\n\",\n",
      "    \"\\nIMPROVED CONTROL\\nAccess to aggregated information about the entire parking operation. When your analysis of data is more efficient and effective, the customers' willingness to pay increases.\\n\",\n",
      "    \"\\nKIOSK & TERMINALS\\nParking terminals are often the direct link between a motorist and a parking system. They need to be tough, reliable, and easy to use. Flowbird\\u00b4s terminals can withstand virtually any environment, be fully customisable and built with the future in mind.\\n\",\n",
      "    \"\\nFLOWBIRD ANALYTICS CONTROL\\nFlowbird Analytics Control is a tool for managing and mapping the deployment of parking enforcement officers. It is used to supervise enforcement areas containing a defined number of parking spaces. Secondly, it enables data to be collected and analysed by extraction from activity reports.\\n\",\n",
      "    \"\\nSUPERVISION FOR ACCURATE REPORTS\\nFlowbird Analytics Control lets you program the available parking spaces and map the enforcement areas where the officers are operating, to provide accurate and precise analyses and reports. Connecting the service to a single server provides the interface between PDAs (enforcement by officers) and ANPR (automatic enforcement vehicle). This provides the supervisor an overview of the checks completed as well as the dematerialized transactions carried out using the ticket machines and the Flowbird application.\\n\",\n",
      "    \"\\nCOMBAT FRAUD\\nFlowbird Analytics Control supervision provides precise guidance for enforcement officers, making it possible to create routes calculated for more efficient and better distributed rounds over service zones to combat parking fraud. Enforcement Officers are directed using geolocation to vehicles suspected of repeated fraud (ANPR pre-check) to avoid scanning all vehicles. So operating costs and recovery rates are optimised. This action, spread over the different round zones, enables rapid and regular collection of payments and fines.\\n\\n\",\n",
      "    \"\\nJOINING UP TOWNS AND CITIES\\nOn a global stage, Flowbird creates value for public transport operators, local authorities and citizens through innovations in automatic fare collection, real-time data management and digital technologies.\\nBy integrating ticketing and journey validation with ID-based and smart, contactless payment systems, and implementing congestion reduction strategies, we are helping towns and cities to plan for a future demanding seamless multi-modal travel.\\nFlowbird's key focus is to design and manufacture innovative quality products and services that can stand alone or be integrated with wider systems for our customers across the globe, backed up with a world class customer service experience.\\n\",\n",
      "    \"\\nAt Flowbird, our mission is to make it easier, safer and quicker for people to access and use public transport. We do this by providing operators and transit authorities of every size with the tools, systems and information they need to serve their customers better.\\nBy optimising operator efficiency and harmonising the flow of people and traffic, we create more sustainable transport systems, improve social cohesion and stimulate economic development.\\n\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# extract raw text\n",
    "raw_text_path = osp.join('../dataset/', \"raw.text\")\n",
    "raw_text = ''\n",
    "try:\n",
    "    f = open(raw_text_path)\n",
    "    raw_text = f.read()\n",
    "except:\n",
    "    raw_text = ''\n",
    "    \n",
    "text_cases = re.split(\"\"\"\n",
    "---\n",
    "\"\"\", raw_text, 0, re.MULTILINE)\n",
    "\n",
    "print(json.dumps(text_cases, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Below is an instruction that describes a context. Answer 3 questions from input base on the provided context.\n",
      "\n",
      "### Instruction:\n",
      " WE ARE FLOWBIRD\n",
      "Flowbird offers end to end Smart mobility, Parking and Electric Vehicle charging solutions. We provide towns\n",
      "and cities with the tools to make mobility in urban areas simple, multimodal and environmentally friendly, and\n",
      "the ability to understand and manage this mobility.\n",
      "Partnering with local administrations and operators for over 65 years, we provide apps, terminals, kerbside\n",
      "management, enforcement - and the software to manage these remotely. We upgrade existing physical terminals to\n",
      "digital terminals with new services and tariffs and open them up to integrate third party apps. Flowbird\n",
      "orchestrates sales, payments, reporting, invoices and fines across multiple endpoints, also providing the data\n",
      "insights needed to inform decisions.\n",
      "\n",
      "\n",
      "### Input:\n",
      "1.   What are some of the challenges faced by Flowbird in implementing its solution?\n",
      "2.   How does Flowbird's solution address these challenges?\n",
      "3.   What are some potential benefits of using Flowbird's solution?\n",
      "\n",
      "### Response:\n",
      "1.   Some of the challenges faced by Flowbird in implementing its solution include:\n",
      "\n",
      "*   Managing the integration of multiple systems and technologies, including mobile apps, terminals, and back-\n",
      "end systems.\n",
      "*   Ensuring compatibility with different types of vehicles and payment methods.\n",
      "*   Providing seamless customer service and support to users.\n",
      "\n",
      "2.   How does Flowbird's solution address these challenges?\n",
      "\n",
      "*   By leveraging advanced technology such as machine learning and artificial intelligence to automate\n",
      "processes and improve user experience.\n",
      "*   By partnering with local administrations and operators to ensure compatibility and accessibility.\n",
      "*   By providing comprehensive training and support to help customers get started and use the system\n",
      "effectively.\n",
      "\n",
      "3.   What are some potential benefits of using Flowbird's solution?\n",
      "\n",
      "*   Improved mobility and accessibility for people and goods in urban areas.\n",
      "*   Reduced traffic congestion and air pollution through the promotion of sustainable transportation options.\n",
      "*   Increased revenue for local governments and businesses through the collection of fees and charges.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# process_raw_text(text_cases[0])\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# save_dataset()\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m case \u001b[39min\u001b[39;00m text_cases:\n\u001b[0;32m----> 5\u001b[0m   process_raw_text(case)\n\u001b[1;32m      6\u001b[0m   save_dataset()\n",
      "Cell \u001b[0;32mIn[10], line 20\u001b[0m, in \u001b[0;36mprocess_raw_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     13\u001b[0m questions_array \u001b[39m=\u001b[39m response_to_array(questions)\n\u001b[1;32m     16\u001b[0m a_prompt \u001b[39m=\u001b[39m answer_prompter\u001b[39m.\u001b[39mgenerate_prompt(\n\u001b[1;32m     17\u001b[0m     text,\n\u001b[1;32m     18\u001b[0m     questions\n\u001b[1;32m     19\u001b[0m )\n\u001b[0;32m---> 20\u001b[0m output \u001b[39m=\u001b[39m pipe(a_prompt)\n\u001b[1;32m     22\u001b[0m output[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mgenerated_text\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m fix_encoding_output(output[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mgenerated_text\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/pipelines/text_generation.py:209\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, text_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    169\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39m    Complete the prompt(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(text_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1109\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\n\u001b[1;32m   1102\u001b[0m         \u001b[39miter\u001b[39m(\n\u001b[1;32m   1103\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1106\u001b[0m         )\n\u001b[1;32m   1107\u001b[0m     )\n\u001b[1;32m   1108\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1109\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1116\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1115\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1116\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1117\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1118\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1015\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1014\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m-> 1015\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[1;32m   1016\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m   1017\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/pipelines/text_generation.py:251\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m prompt_text \u001b[39m=\u001b[39m model_inputs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mprompt_text\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    250\u001b[0m \u001b[39m# BS x SL\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m generated_sequence \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mgenerate(input_ids\u001b[39m=\u001b[39;49minput_ids, attention_mask\u001b[39m=\u001b[39;49mattention_mask, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgenerate_kwargs)\n\u001b[1;32m    252\u001b[0m out_b \u001b[39m=\u001b[39m generated_sequence\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    253\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/generation/utils.py:1509\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1504\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnum_return_sequences has to be 1 when doing greedy search, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1505\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut is \u001b[39m\u001b[39m{\u001b[39;00mgeneration_config\u001b[39m.\u001b[39mnum_return_sequences\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1506\u001b[0m         )\n\u001b[1;32m   1508\u001b[0m     \u001b[39m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgreedy_search(\n\u001b[1;32m   1510\u001b[0m         input_ids,\n\u001b[1;32m   1511\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1512\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1513\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[1;32m   1514\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[1;32m   1515\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[1;32m   1516\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1517\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1518\u001b[0m         streamer\u001b[39m=\u001b[39;49mstreamer,\n\u001b[1;32m   1519\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1520\u001b[0m     )\n\u001b[1;32m   1522\u001b[0m \u001b[39melif\u001b[39;00m is_contrastive_search_gen_mode:\n\u001b[1;32m   1523\u001b[0m     \u001b[39mif\u001b[39;00m generation_config\u001b[39m.\u001b[39mnum_return_sequences \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/generation/utils.py:2322\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2319\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2321\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2322\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   2323\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   2324\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2325\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   2326\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   2327\u001b[0m )\n\u001b[1;32m   2329\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2330\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[39m=\u001b[39m old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[39m=\u001b[39m old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    166\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:688\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    685\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m    687\u001b[0m \u001b[39m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 688\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m    689\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[1;32m    690\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    691\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    692\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    693\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    694\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    695\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    696\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    697\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    698\u001b[0m )\n\u001b[1;32m    700\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    701\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[39m=\u001b[39m old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[39m=\u001b[39m old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    166\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:578\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    570\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    571\u001b[0m         create_custom_forward(decoder_layer),\n\u001b[1;32m    572\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    576\u001b[0m     )\n\u001b[1;32m    577\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 578\u001b[0m     layer_outputs \u001b[39m=\u001b[39m decoder_layer(\n\u001b[1;32m    579\u001b[0m         hidden_states,\n\u001b[1;32m    580\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    581\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    582\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    583\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    584\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    585\u001b[0m     )\n\u001b[1;32m    587\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    589\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[39m=\u001b[39m old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[39m=\u001b[39m old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    166\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:293\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    290\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    292\u001b[0m \u001b[39m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(\n\u001b[1;32m    294\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    295\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    296\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    297\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    298\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    299\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    300\u001b[0m )\n\u001b[1;32m    301\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n\u001b[1;32m    303\u001b[0m \u001b[39m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[39m=\u001b[39m old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[39m=\u001b[39m old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    166\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py:199\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    197\u001b[0m query_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_proj(hidden_states)\u001b[39m.\u001b[39mview(bsz, q_len, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim)\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m    198\u001b[0m key_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_proj(hidden_states)\u001b[39m.\u001b[39mview(bsz, q_len, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim)\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[0;32m--> 199\u001b[0m value_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv_proj(hidden_states)\u001b[39m.\u001b[39mview(bsz, q_len, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim)\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m    201\u001b[0m kv_seq_len \u001b[39m=\u001b[39m key_states\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\n\u001b[1;32m    202\u001b[0m \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[39m=\u001b[39m old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[39m=\u001b[39m old_forward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    166\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39m_hf_hook\u001b[39m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/bitsandbytes/nn/modules.py:320\u001b[0m, in \u001b[0;36mLinear8bitLt.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m x\u001b[39m.\u001b[39mdtype:\n\u001b[1;32m    318\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mto(x\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m--> 320\u001b[0m out \u001b[39m=\u001b[39m bnb\u001b[39m.\u001b[39;49mmatmul(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, bias\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate)\n\u001b[1;32m    322\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mhas_fp16_weights:\n\u001b[1;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mCB \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mCxB \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m         \u001b[39m# we converted 8-bit row major to turing/ampere format in the first inference pass\u001b[39;00m\n\u001b[1;32m    325\u001b[0m         \u001b[39m# we no longer need the row-major weight\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:500\u001b[0m, in \u001b[0;36mmatmul\u001b[0;34m(A, B, out, state, threshold, bias)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[39mif\u001b[39;00m threshold \u001b[39m>\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m    499\u001b[0m     state\u001b[39m.\u001b[39mthreshold \u001b[39m=\u001b[39m threshold\n\u001b[0;32m--> 500\u001b[0m \u001b[39mreturn\u001b[39;00m MatMul8bitLt\u001b[39m.\u001b[39;49mapply(A, B, out, bias, state)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[39m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[39m=\u001b[39m _functorch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mapply(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39msetup_context \u001b[39m==\u001b[39m _SingleLevelFunction\u001b[39m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mstaticmethod. For more details, please see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:323\u001b[0m, in \u001b[0;36mMatMul8bitLt.forward\u001b[0;34m(ctx, A, B, out, bias, state)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(A\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m    322\u001b[0m     A \u001b[39m=\u001b[39m A\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, A\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mcontiguous()\n\u001b[0;32m--> 323\u001b[0m CA, CAt, SCA, SCAt, coo_tensorA \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mdouble_quant(A\u001b[39m.\u001b[39;49mto(torch\u001b[39m.\u001b[39;49mfloat16), threshold\u001b[39m=\u001b[39;49mstate\u001b[39m.\u001b[39;49mthreshold)\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m state\u001b[39m.\u001b[39mthreshold \u001b[39m>\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mand\u001b[39;00m coo_tensorA \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[39mif\u001b[39;00m state\u001b[39m.\u001b[39mhas_fp16_weights:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/bitsandbytes/functional.py:1687\u001b[0m, in \u001b[0;36mdouble_quant\u001b[0;34m(A, col_stats, row_stats, out_col, out_row, threshold)\u001b[0m\n\u001b[1;32m   1685\u001b[0m     coo_tensor\u001b[39m.\u001b[39mrowidx \u001b[39m=\u001b[39m val\n\u001b[1;32m   1686\u001b[0m     coo_tensor\u001b[39m.\u001b[39mcolidx \u001b[39m=\u001b[39m coo_tensor\u001b[39m.\u001b[39mcolidx[idx]\n\u001b[0;32m-> 1687\u001b[0m     coo_tensor\u001b[39m.\u001b[39mvalues \u001b[39m=\u001b[39m coo_tensor\u001b[39m.\u001b[39;49mvalues[idx]\n\u001b[1;32m   1688\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1689\u001b[0m     lib\u001b[39m.\u001b[39mcdouble_rowcol_quant(\n\u001b[1;32m   1690\u001b[0m         ptrA,\n\u001b[1;32m   1691\u001b[0m         ptrRowStats,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1701\u001b[0m         ct\u001b[39m.\u001b[39mc_int32(cols),\n\u001b[1;32m   1702\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# process_raw_text(text_cases[0])\n",
    "# save_dataset()\n",
    "\n",
    "for case in text_cases:\n",
    "  process_raw_text(case)\n",
    "  save_dataset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FLOWBIRD STATISTIC IN 2023\n",
    "80 Countries\n",
    "4,350 Cities\n",
    "350,000,000 Transactions per year\n",
    "2,000,000 Tickets sold every day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    \"\",\n",
      "    \"Some of the challenges faced by Flowbird in implementing its solution include:\\n\\n*   Managing the integration of multiple systems and technologies, including mobile apps, terminals, and back-end systems.\\n*   Ensuring compatibility with different types of vehicles and payment methods.\\n*   Providing seamless customer service and support to users.\\n\\n\",\n",
      "    \"How does Flowbird's solution address these challenges?\\n\\n*   By leveraging advanced technology such as machine learning and artificial intelligence to automate processes and improve user experience.\\n*   By partnering with local administrations and operators to ensure compatibility and accessibility.\\n*   By providing comprehensive training and support to help customers get started and use the system effectively.\\n\\n\",\n",
      "    \"What are some potential benefits of using Flowbird's solution?\\n\\n*   Improved mobility and accessibility for people and goods in urban areas.\\n*   Reduced traffic congestion and air pollution through the promotion of sustainable transportation options.\\n*   Increased revenue for local governments and businesses through the collection of fees and charges.\"\n",
      "]\n",
      "[\n",
      "    \"\",\n",
      "    \"What are some of the challenges faced by Flowbird in implementing its solution?\\n\",\n",
      "    \"How does Flowbird's solution address these challenges?\\n\",\n",
      "    \"What are some potential benefits of using Flowbird's solution?\"\n",
      "]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# print(json.dumps(answers_array, indent=4))\n",
    "# print(json.dumps(questions_array, indent=4))\n",
    "# print(json.dumps(dataset, indent=4))\n",
    "\n",
    "# dataset = []\n",
    "\n",
    "# save_dataset()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
